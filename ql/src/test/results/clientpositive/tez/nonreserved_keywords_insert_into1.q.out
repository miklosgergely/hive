PREHOOK: query: DROP TABLE `insert`
PREHOOK: type: DROPTABLE
POSTHOOK: query: DROP TABLE `insert`
POSTHOOK: type: DROPTABLE
PREHOOK: query: CREATE TABLE `insert` (key INT, `as` STRING)
PREHOOK: type: CREATETABLE
PREHOOK: Output: database:default
PREHOOK: Output: default@insert
POSTHOOK: query: CREATE TABLE `insert` (key INT, `as` STRING)
POSTHOOK: type: CREATETABLE
POSTHOOK: Output: database:default
POSTHOOK: Output: default@insert
PREHOOK: query: EXPLAIN INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: EXPLAIN INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-0
      Move Operator
        table:{"name:":"default.insert"}
        Stage-2
          Dependency Collection{}
            Stage-1
              Reducer 3
              File Output Operator [FS_14]
                Group By Operator [GBY_12] (rows=1 width=880)
                  Output:["_col0","_col1"],aggregations:["compute_stats(VALUE._col0)","compute_stats(VALUE._col1)"]
                <-Reducer 2 [CUSTOM_SIMPLE_EDGE]
                  File Output Operator [FS_7]
                    table:{"name:":"default.insert"}
                    Select Operator [SEL_6] (rows=100 width=95)
                      Output:["_col0","_col1"]
                      Limit [LIM_5] (rows=100 width=178)
                        Number of rows:100
                        Select Operator [SEL_4] (rows=100 width=178)
                          Output:["_col0","_col1"]
                        <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                          PARTITION_ONLY_SHUFFLE [RS_17]
                            Limit [LIM_16] (rows=100 width=178)
                              Number of rows:100
                              Select Operator [SEL_15] (rows=500 width=178)
                                Output:["_col0","_col1"]
                                TableScan [TS_0] (rows=500 width=178)
                                  default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
                  PARTITION_ONLY_SHUFFLE [RS_11]
                    Group By Operator [GBY_10] (rows=1 width=864)
                      Output:["_col0","_col1"],aggregations:["compute_stats(key, 'hll')","compute_stats(as, 'hll')"]
                      Select Operator [SEL_9] (rows=100 width=95)
                        Output:["key","as"]
                         Please refer to the previous Select Operator [SEL_6]

PREHOOK: query: INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
POSTHOOK: Lineage: insert.as SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: insert.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: SELECT SUM(HASH(hash)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (hash) FROM `insert`
) t
PREHOOK: type: QUERY
PREHOOK: Input: default@insert
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT SUM(HASH(hash)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (hash) FROM `insert`
) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@insert
POSTHOOK: Output: hdfs://### HDFS PATH ###
10226524244
PREHOOK: query: EXPLAIN INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: EXPLAIN INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-0
      Move Operator
        table:{"name:":"default.insert"}
        Stage-2
          Dependency Collection{}
            Stage-1
              Reducer 3
              File Output Operator [FS_14]
                Group By Operator [GBY_12] (rows=1 width=880)
                  Output:["_col0","_col1"],aggregations:["compute_stats(VALUE._col0)","compute_stats(VALUE._col1)"]
                <-Reducer 2 [CUSTOM_SIMPLE_EDGE]
                  File Output Operator [FS_7]
                    table:{"name:":"default.insert"}
                    Select Operator [SEL_6] (rows=100 width=95)
                      Output:["_col0","_col1"]
                      Limit [LIM_5] (rows=100 width=178)
                        Number of rows:100
                        Select Operator [SEL_4] (rows=100 width=178)
                          Output:["_col0","_col1"]
                        <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                          PARTITION_ONLY_SHUFFLE [RS_17]
                            Limit [LIM_16] (rows=100 width=178)
                              Number of rows:100
                              Select Operator [SEL_15] (rows=500 width=178)
                                Output:["_col0","_col1"]
                                TableScan [TS_0] (rows=500 width=178)
                                  default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
                  PARTITION_ONLY_SHUFFLE [RS_11]
                    Group By Operator [GBY_10] (rows=1 width=864)
                      Output:["_col0","_col1"],aggregations:["compute_stats(key, 'hll')","compute_stats(as, 'hll')"]
                      Select Operator [SEL_9] (rows=100 width=95)
                        Output:["key","as"]
                         Please refer to the previous Select Operator [SEL_6]

PREHOOK: query: INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: INSERT INTO TABLE `insert` SELECT * FROM src LIMIT 100
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
POSTHOOK: Lineage: insert.as SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: insert.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: SELECT SUM(HASH(sum)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (sum) FROM `insert`
) t
PREHOOK: type: QUERY
PREHOOK: Input: default@insert
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT SUM(HASH(sum)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (sum) FROM `insert`
) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@insert
POSTHOOK: Output: hdfs://### HDFS PATH ###
20453048488
PREHOOK: query: SELECT COUNT(*) FROM `insert`
PREHOOK: type: QUERY
PREHOOK: Input: default@insert
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT COUNT(*) FROM `insert`
POSTHOOK: type: QUERY
POSTHOOK: Input: default@insert
POSTHOOK: Output: hdfs://### HDFS PATH ###
200
PREHOOK: query: EXPLAIN INSERT OVERWRITE TABLE `insert` SELECT * FROM src LIMIT 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: EXPLAIN INSERT OVERWRITE TABLE `insert` SELECT * FROM src LIMIT 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
Plan optimized by CBO.

Vertex dependency in root stage
Reducer 2 <- Map 1 (CUSTOM_SIMPLE_EDGE)
Reducer 3 <- Reducer 2 (CUSTOM_SIMPLE_EDGE)

Stage-3
  Stats Work{}
    Stage-0
      Move Operator
        table:{"name:":"default.insert"}
        Stage-2
          Dependency Collection{}
            Stage-1
              Reducer 3
              File Output Operator [FS_14]
                Group By Operator [GBY_12] (rows=1 width=880)
                  Output:["_col0","_col1"],aggregations:["compute_stats(VALUE._col0)","compute_stats(VALUE._col1)"]
                <-Reducer 2 [CUSTOM_SIMPLE_EDGE]
                  File Output Operator [FS_7]
                    table:{"name:":"default.insert"}
                    Select Operator [SEL_6] (rows=10 width=95)
                      Output:["_col0","_col1"]
                      Limit [LIM_5] (rows=10 width=178)
                        Number of rows:10
                        Select Operator [SEL_4] (rows=10 width=178)
                          Output:["_col0","_col1"]
                        <-Map 1 [CUSTOM_SIMPLE_EDGE] vectorized
                          PARTITION_ONLY_SHUFFLE [RS_17]
                            Limit [LIM_16] (rows=10 width=178)
                              Number of rows:10
                              Select Operator [SEL_15] (rows=500 width=178)
                                Output:["_col0","_col1"]
                                TableScan [TS_0] (rows=500 width=178)
                                  default@src,src,Tbl:COMPLETE,Col:COMPLETE,Output:["key","value"]
                  PARTITION_ONLY_SHUFFLE [RS_11]
                    Group By Operator [GBY_10] (rows=1 width=864)
                      Output:["_col0","_col1"],aggregations:["compute_stats(key, 'hll')","compute_stats(as, 'hll')"]
                      Select Operator [SEL_9] (rows=10 width=95)
                        Output:["key","as"]
                         Please refer to the previous Select Operator [SEL_6]

PREHOOK: query: INSERT OVERWRITE TABLE `insert` SELECT * FROM src LIMIT 10
PREHOOK: type: QUERY
PREHOOK: Input: default@src
PREHOOK: Output: default@insert
POSTHOOK: query: INSERT OVERWRITE TABLE `insert` SELECT * FROM src LIMIT 10
POSTHOOK: type: QUERY
POSTHOOK: Input: default@src
POSTHOOK: Output: default@insert
POSTHOOK: Lineage: insert.as SIMPLE [(src)src.FieldSchema(name:value, type:string, comment:default), ]
POSTHOOK: Lineage: insert.key EXPRESSION [(src)src.FieldSchema(name:key, type:string, comment:default), ]
PREHOOK: query: SELECT SUM(HASH(add)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (add) FROM `insert`
) t
PREHOOK: type: QUERY
PREHOOK: Input: default@insert
PREHOOK: Output: hdfs://### HDFS PATH ###
POSTHOOK: query: SELECT SUM(HASH(add)) FROM (
    SELECT TRANSFORM(*) USING 'tr \t _' AS (add) FROM `insert`
) t
POSTHOOK: type: QUERY
POSTHOOK: Input: default@insert
POSTHOOK: Output: hdfs://### HDFS PATH ###
-826625916
PREHOOK: query: DROP TABLE `insert`
PREHOOK: type: DROPTABLE
PREHOOK: Input: default@insert
PREHOOK: Output: default@insert
POSTHOOK: query: DROP TABLE `insert`
POSTHOOK: type: DROPTABLE
POSTHOOK: Input: default@insert
POSTHOOK: Output: default@insert
